<!doctype html>
<html lang="en" data-theme="light">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="css/pico.min.css">
    <title>Trustworthy Autonomous Systems</title>
  </head>
  <body>
    <main class="container">

		<article>
			<header>
				<hgroup>
					<h2>Perspectives on Trustworthy Autonomous Systems</h2>
					<h2>A scoping study</h2>
				</hgroup>
			</header>
			
			
			
			<h3>Summary</h3>
			<p>
			The Perspectives on Trustworthy Autonomous Systems study is a year long study conducted by <strong>Dr Pepita Barnard</strong> and <strong>Dr Jeremie Clos</strong> on the influence of local, national, institutional and professional views and understanding of industry practitioners and academics on AI development and education. This scoping study is supported by the <a href="https://www.tas.ac.uk/">Trustworthy Autonomous Systems hub</a> (learn more about the TAS at <a href="https://www.tas.ac.uk/aboutus/overview/">tas.ac.uk</a>), a UK-wide research initiative created to research and advance trustworthiness in artificial intelligence and automated decision-making systems. As part of this study, we are travelling to academic and industry labs to conduct workshops using Moral IT cards and establish collaborations on joint topics of interest.</p>
			
			
			<p>Our goal is two-fold:</p> 
			<ol>
				<li>Research approaches, challenges, and opportunities to trustworthy autonomous systems (e.g., human-centred/responsible/explainable/interpretable AI, Human-AI Interaction, Natural Language Processing etc.) in an academic and industrial context, with the dual objective of (1) building a survey study and (2) designing a workshop for the CHI 2023 conference to push a global research agenda.</li>
				<li>Discuss educational efforts on teaching curriculum development by identifying core topics and activities that reflect the multidisciplinary needs of the current and future <abbr title="Trustworthy Autonomous Systems">TAS</abbr> researchers and engineers.</li>
			</ol>
		
			
			
			<p>The rest of this page is structured as follows:</p>
			<ol>
				<li><a href="#details">Details of the study</a></li>
				<li><a href="#questions">How the workshop is run</a></li>
				<li><a href="#who">Who is running the study</a></li>
				<li><a href="#faq">Frequently asked questions</a></li>
				<li><a href="#paperwork">Documentation of the project</a></li>
			</ol>
			
			<h3 id="details">1. Details of the study</h3>
			<p>As part of the TAS hub, our focus long-term is to establish strategic partnerships for the purpose of studying trust and trustworthiness as they relate to autonomous systems, through the redaction of joint papers, the hosting of joint workshops, and other research activities. 
			The objective of our visits are therefore to lay the foundations of such partnership through the production of a survey on attitudes and perspectives towards trustworthy autonomous systems-related issues and challenges from universities and institutions across the world. 
			As such, we are planning to use the Moral IT cards - a tool developed in the Horizon research centre to guide structured discussions about computer ethics. <a href="https://lachlansresearch.com/the-moral-it-legal-it-decks/">Moral IT cards</a> can help facilitate discussion around the broad themes of trust, trustworthiness and how they may be achieved from both a social and a technical perspective.</p>


			<h3 id="questions">2. How the workshop is run</h3>
			<p>
			During the workshop, we will ask you to reflect on the following questions:

			<ol>
				<li>How do different countries approach the development, study, and use of human-centred autonomous systems (if you have a view on this)? </li>
				<li>How do they address and focus on making AI / AS trustworthy, so that they are used by people who can and do rightfully trust them.</li>
				<li>How does the USA approach the development, study, and use of human-centred AI / AS (if you have a view on this)?</li>
				<li>What does human-centred AI mean to you?  </li>
				<li>What does trustworthy autonomous systems mean to you? </li>
				<li>Field(s) do you work in / with? </li>
				<li>How does your work relate to autonomous systems / artificial intelligence? (your context) </li>
				<li>Think about a specific technology / technologies: what technologies do you use or study? </li>
				<li>What tools are used to assess / appraise AI / AS?</li>
				<li>How do you assess / appraise trustworthiness of AI / AS?</li>
				<li>Existing tools, techniques, frameworks, checklists you may already be using?</li>
				<li>What do you think are overrated problems?</li>
				<li>What do you think are underrated problems?</li>
				<li>What do you think are the most important topics in the short term?</li>
				<li>What do you think are the most important topics in the long term?</li>
				<li>Discussion of educational efforts on teaching curriculum development by identifying core topics and activities that reflect the multidisciplinary needs of the current and future TAS researchers and engineers.</li>
			</ol>
			
			</p>
			

			<h3 id="who">3. Who is running the study</h3>
			<p><strong>Pepita</strong> has a background in healthcare provision, clinical informatics and health services research. I am a human factors research fellow at Horizon Digital Economy Research Institute, School of Computer Science, University of Nottingham. In our cobot maker space, my AI projects involve humans with cobots, telepresence robots, other intelligent agents and devices for industrial and domestic settings. </p>

			<p><strong>Jeremie</strong> has a background in traditional computer science, information retrieval and machine learning. He is a research fellow in natural language processing in the TAS and a teaching associate in the School of Computer Science working on curriculum development for human-centred AI modules.
			</p>


			<h3 id="faq">4. Frequently asked questions</h3>
			
				<ul>
					<li><strong>What are you aiming to achieve?</strong></li>
					
					<p>We are interested in studying trustworthy artificial intelligence. However, trustworthiness is a multifaceted concept that is understood and tackled differently depending on the person you ask. Our aim is to have a deeper understanding of the core differences in how we understand trustworthiness by comparing researchers and practitioners from the US with researchers and practitioners from the UK.</p> 
					
					<li><strong>Who is involved?</strong></li>
					
					<p>The lead researcher involved in the study is Dr Pepita Barnard, who is accompanied by Dr Jeremie Clos.</p>
					
					<li><strong>What do you want to do during the meeting?</strong></li>
					
					<p>We would like to use the Moral IT cards as a framework for our conversation, eliciting your views on trustworthiness in artificial intelligence and autonomous systems in general.</p> 
					
					<li><strong>What is the purpose of the data collection?</strong></li>
					
					<p>Our plan is to use this data to write a survey paper on the diverse views on trustworthiness in artificial intelligence, and use this paper to spur a larger collaborative effort such as a conference workshop in a large interdisciplinary conference (e.g., CHI).</p> 
					
					<li><strong>What is the reason for recording?</strong></li> 
					
					<p>The recording helps us avoid copious notetaking while trying to talk. Recording for collaboration requires the agreement from those collaborators who are present. The study is extra, and it must be consented to in writing by each participant. The recording (or more accurately, the recording of those who consented) can also be used for the illustrative study.</p>		
				</ul>	
			

			<h3 id="paperwork">5. General paperwork</h3>
			
				
			
				The <a href="files/information-sheet.pdf">information sheet</a> will tell you more details about the benefits and risk of the research, how we use your data (during and after the study), and how to withdraw from the study.<br/>
				The <a href="files/privacy-notice.pdf">privacy notice</a> will give you a lot more details about how we manage your data and your rights under GDPR.<br/>
				Unfortunately we cannot put our consent form online as it contains personal details about the researchers involved in the study.
				
			
			

			<footer>
			<h3>Contact us</h3>
			<p>
				While our travel is limited by COVID conditions, teaching duties, and budgetary concerns we are always looking for opportunities to meet new people. If you are interested in potential collaborations, please <a href="mailto:pepita.barnard@nottingham.ac.uk,jeremie.clos@nottingham.ac.uk?subject=About the IPoTAS Study">e-mail us</a>.
			</p>
	
			</footer>
		</article>
		
			
    </main>
  </body>
</html>

